{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv, os, shutil, collections, copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anki CSV export file manipulations\n",
    "\n",
    "This code takse in csv file generated by Anki and outputs several csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#INPUT\n",
    "#folder = 'sample' # create this folder and place the exported file\n",
    "folder = 'all'\n",
    "#export_filename = 'English_Vocabulary_Sample.csv'\n",
    "export_filename = 'English_Vocabulary3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate a dictionary from Anki export file.\n",
    "Note:\n",
    "Only GRE words have proper Serial No. Rest words have 99999 as Serial No.\n",
    "\"\"\"\n",
    "\n",
    "word_db = []\n",
    "\n",
    "with open(folder + os.sep + export_filename, mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    Serial_No = 1\n",
    "    for line in reader:\n",
    "        row = {} \n",
    "        row['Word'] = line[0]\n",
    "        row['Word audio'] = line[1]\n",
    "        \n",
    "        aud_files = []\n",
    "        for i in range(len(row['Word audio'])):\n",
    "            if (row['Word audio'][i]==':'):\n",
    "                aud_file = \"\"\n",
    "                for j in range(i+1, len(row['Word audio'])):\n",
    "                    if (row['Word audio'][j]==']'):\n",
    "                        break\n",
    "                    aud_file += row['Word audio'][j]\n",
    "                aud_files.append(aud_file.strip(' '))\n",
    "        row['Word audio2'] = aud_files # list of Word audio files\n",
    "        \n",
    "        row['POS'] = line[2]\n",
    "        row['Other form'] = line[3]\n",
    "        row['Meaning'] = line[4]\n",
    "        row['Example'] = line[5]\n",
    "        row['Picture'] = line[6]\n",
    "        \n",
    "        row['Picture'] = row['Picture']\n",
    "        img_files = []\n",
    "        for i in range(len(row['Picture'])):\n",
    "            if (row['Picture'][i]=='='):\n",
    "                img_file = \"\"\n",
    "                for j in range(i+1, len(row['Picture'])):\n",
    "                    if (row['Picture'][j]=='/'):\n",
    "                        break\n",
    "                    img_file += row['Picture'][j]\n",
    "                img_files.append(img_file.strip(' '))\n",
    "        row['Picture2'] = img_files # list of images files\n",
    "        \n",
    "        row['Mnemonic'] = line[7]\n",
    "        row['Synonym'] = line[8]\n",
    "        row['Antonym'] = line[9]\n",
    "        row['Note'] = line[10]\n",
    "        \n",
    "        #row['Note'] = row['Note'].replace('\"', '')\n",
    "        img_files = []\n",
    "        for i in range(len(row['Note'])):\n",
    "            if (row['Note'][i]=='='):\n",
    "                img_file = \"\"\n",
    "                for j in range(i+1, len(row['Note'])):\n",
    "                    if (row['Note'][j]=='/'):\n",
    "                        break\n",
    "                    img_file += row['Note'][j]\n",
    "                img_files.append(img_file.strip(' '))\n",
    "        row['Note Image'] = img_files # list of images files in Note\n",
    "        \n",
    "        row['Multimedia Example'] = line[11]\n",
    "        \n",
    "        mul_files = []\n",
    "        for i in range(len(row['Multimedia Example'])):\n",
    "            if (row['Multimedia Example'][i]==':'):\n",
    "                mul_file = \"\"\n",
    "                for j in range(i+1, len(row['Multimedia Example'])):\n",
    "                    if (row['Multimedia Example'][j]==']'):\n",
    "                        break\n",
    "                    mul_file += row['Multimedia Example'][j]\n",
    "                mul_files.append(mul_file.strip(' '))\n",
    "        row['Multimedia Example2'] = mul_files # list of Multimedia Example files\n",
    "        \n",
    "        row['Tags'] = line[12]\n",
    "        \n",
    "        row['Tags2'] = row['Tags'].split(' ') # list of tags\n",
    "        \n",
    "        if 'EV_GRE' in row['Tags2']:\n",
    "            row['Word No'] = Serial_No\n",
    "            Serial_No += 1\n",
    "        else:\n",
    "            row['Word No'] = 99999 # Serial No for non GRE words\n",
    "        \n",
    "        word_db.append(row)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in word_db:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Writes out the generated word_db\n",
    "\"\"\"\n",
    "\n",
    "with open(folder + os.sep + 'word_db.csv','wb') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(word_db[0].keys()) # keys in top row\n",
    "    for i in word_db:\n",
    "        w.writerow(i.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copying media files to folders\n",
    "\n",
    "Google drive creates problem when generated shared links if there are more than 3500 files in a folder.<br>\n",
    "So, I am copying media files to folders."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path = r'C:\\Users\\Gyan Tatiya\\AppData\\Roaming\\Anki2\\User 2\\collection.media'\n",
    "\n",
    "if not os.path.exists(path + os.sep + 'Word audio2'):\n",
    "    os.makedirs(path + os.sep + 'Word audio2')\n",
    "if not os.path.exists(path + os.sep + 'Picture2'):\n",
    "    os.makedirs(path + os.sep + 'Picture2')\n",
    "if not os.path.exists(path + os.sep + 'Note Image'):\n",
    "    os.makedirs(path + os.sep + 'Note Image')\n",
    "if not os.path.exists(path + os.sep + 'Multimedia Example2'):\n",
    "    os.makedirs(path + os.sep + 'Multimedia Example2')\n",
    "\n",
    "for i in word_db:\n",
    "    for IMA_file in i['Word audio2']:\n",
    "        shutil.copy(path + os.sep + IMA_file, path + os.sep + 'Word audio2')\n",
    "    for IMA_file in i['Picture2']:\n",
    "        shutil.copy(path + os.sep + IMA_file, path + os.sep + 'Picture2')\n",
    "    for IMA_file in i['Note Image']:\n",
    "        shutil.copy(path + os.sep + IMA_file, path + os.sep + 'Note Image')\n",
    "    for IMA_file in i['Multimedia Example2']:\n",
    "        shutil.copy(path + os.sep + IMA_file, path + os.sep + 'Multimedia Example2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload files\n",
    "Go to google drive and upload the 4 generated folder. <br>\n",
    "## Input files:\n",
    "Generate csv files that has shared links, and remane: FlashVocab_sheet - Multimedia Example2.csv, FlashVocab_sheet - Note Image.csv, FlashVocab_sheet - Picture2.csv, FlashVocab_sheet - Word audio2.csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with open(folder + os.sep + 'FlashVocab_sheet - Multimedia Example2.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    mul_dict = {}\n",
    "    for i in reader:\n",
    "        mul_dict[i[1]] = i[3]\n",
    "#print(mul_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with open(folder + os.sep + 'FlashVocab_sheet - Note Image.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    not_dict = {}\n",
    "    for i in reader:\n",
    "        not_dict[i[1]] = i[3]\n",
    "#print(not_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with open(folder + os.sep + 'FlashVocab_sheet - Picture2.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    pic_dict = {}\n",
    "    for i in reader:\n",
    "        pic_dict[i[1]] = i[3]\n",
    "#print(pic_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with open(folder + os.sep + 'FlashVocab_sheet - Word audio2.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    aud_dict = {}\n",
    "    for i in reader:\n",
    "        aud_dict[i[1]] = i[3]\n",
    "#print(aud_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "Updating word_db by inserting shared links\n",
    "\"\"\"\n",
    "\n",
    "for i in range(len(word_db)):\n",
    "    links = []\n",
    "    for IMA_file in word_db[i]['Word audio2']:\n",
    "        link = aud_dict[IMA_file]\n",
    "        links.append(link)\n",
    "    word_db[i]['Word audio2 links'] = links\n",
    "    \n",
    "    links = []\n",
    "    for IMA_file in word_db[i]['Picture2']:\n",
    "        link = pic_dict[IMA_file]\n",
    "        links.append(link)\n",
    "    word_db[i]['Picture2 links'] = links\n",
    "    \n",
    "    links = []\n",
    "    for IMA_file in word_db[i]['Note Image']:\n",
    "        link = not_dict[IMA_file]\n",
    "        links.append(link)\n",
    "    word_db[i]['Note Image links'] = links\n",
    "    \n",
    "    links = []\n",
    "    for IMA_file in word_db[i]['Multimedia Example2']:\n",
    "        link = mul_dict[IMA_file]\n",
    "        links.append(link)\n",
    "    word_db[i]['Multimedia Example2 links'] = links"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "Writes out the generated word_db\n",
    "\"\"\"\n",
    "\n",
    "with open(folder + os.sep + 'word_db_links.csv','wb') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(word_db[0].keys()) # keys in top row\n",
    "    for i in word_db:\n",
    "        w.writerow(i.values())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "Updating word_db by inserting export shared links\n",
    "https://drive.google.com/uc?export=view&id={fileId}\n",
    "\"\"\"\n",
    "\n",
    "for i in range(len(word_db)):\n",
    "    links = []\n",
    "    for IMA_file in word_db[i]['Word audio2 links']:\n",
    "        file_id = IMA_file.split('/')[5]\n",
    "        export_link = 'https://drive.google.com/uc?export=view&id=' + file_id\n",
    "        links.append(export_link)\n",
    "    word_db[i]['Word audio2 export links'] = links\n",
    "    \n",
    "    links = []\n",
    "    for IMA_file in word_db[i]['Picture2 links']:\n",
    "        file_id = IMA_file.split('/')[5]\n",
    "        export_link = 'https://drive.google.com/uc?export=view&id=' + file_id\n",
    "        links.append(export_link)\n",
    "    word_db[i]['Picture2 export links'] = links\n",
    "    \n",
    "    links = []\n",
    "    for IMA_file in word_db[i]['Note Image links']:\n",
    "        file_id = IMA_file.split('/')[5]\n",
    "        export_link = 'https://drive.google.com/uc?export=view&id=' + file_id\n",
    "        links.append(export_link)\n",
    "    word_db[i]['Note Image export links'] = links\n",
    "    \n",
    "    links = []\n",
    "    for IMA_file in word_db[i]['Multimedia Example2 links']:\n",
    "        file_id = IMA_file.split('/')[5]\n",
    "        export_link = 'https://drive.google.com/uc?export=view&id=' + file_id\n",
    "        links.append(export_link)\n",
    "    word_db[i]['Multimedia Example2 export links'] = links"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "Writes out the generated word_db\n",
    "\"\"\"\n",
    "\n",
    "with open(folder + os.sep + 'word_db_links_export.csv','wb') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(word_db[0].keys()) # keys in top row\n",
    "    for i in word_db:\n",
    "        w.writerow(i.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Updating word_db by Google Cloud Storage links\n",
    "https://storage.googleapis.com/my-first-cloud-app-gtatiya.appspot.com/FlashVocab/{filename}\n",
    "\"\"\"\n",
    "\n",
    "for i in range(len(word_db)):\n",
    "    links = []\n",
    "    for IMA_file in word_db[i]['Picture2']:\n",
    "        link = \"https://storage.googleapis.com/my-first-cloud-app-gtatiya.appspot.com/FlashVocab/\"+IMA_file\n",
    "        links.append(link)\n",
    "    word_db[i]['Picture2 GCS links'] = links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Writes out the generated word_db\n",
    "\"\"\"\n",
    "\n",
    "with open(folder + os.sep + 'word_db_links_GCS.csv','wb') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(word_db[0].keys()) # keys in top row\n",
    "    for i in word_db:\n",
    "        w.writerow(i.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function sorts the dictionary based on keys and writes a CSV file\n",
    "\"\"\"\n",
    "\n",
    "def sort_dict_column(filename, dict_db):\n",
    "    with open(filename,'wb') as f:\n",
    "        w = csv.writer(f)\n",
    "        temp = sorted(dict_db[0].keys())\n",
    "        w.writerow(temp)\n",
    "        for i in dict_db:\n",
    "            i = collections.OrderedDict(sorted(i.items()))\n",
    "            w.writerow((i.values()))\n",
    "\n",
    "#sort_dict_column(folder + os.sep + 'word_db_links_export_sorted.csv', word_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRE words only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate a dictionary from word_db for GRE words based on tags\n",
    "\"\"\"\n",
    "\n",
    "word_gre_db = []\n",
    "\n",
    "for i in word_db:\n",
    "    if 'EV_GRE' in i['Tags2']:\n",
    "        word_gre_db.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Writes out the generated word_gre_db\n",
    "word_db_links_export_gre.csv\n",
    "word_db_links_GCP_gre.csv\n",
    "\"\"\"\n",
    "\n",
    "with open(folder + os.sep + 'word_db_links_export_gre.csv','wb') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(word_gre_db[0].keys()) # keys in top row\n",
    "    for i in word_gre_db:\n",
    "        w.writerow(i.values())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "sort_dict_column(folder + os.sep + 'word_db_links_export_gre_sorted.csv', word_gre_db)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "This it to be used in Words.java in MyWordDataDisplay project\n",
    "\"\"\"\n",
    "\n",
    "words_tem = word_gre_db\n",
    "#words_tem = word_db\n",
    "\n",
    "java_commands = open('java_commands.txt', 'w')\n",
    "java_commands.close()\n",
    "\n",
    "n = 0\n",
    "for i in words_tem:\n",
    "    del i['Mnemonic'] # delete Mnemonic because it has '\"' character\n",
    "    del i['Note'] # I am not going to use Note\n",
    "    del i['Note Image export links'] # I am not going to use Note\n",
    "    del i['Other form'] # I am not going to use Other form\n",
    "    del i['Picture'] # I am not going to use Picture\n",
    "    del i['Word audio2'] # I am not going to use \n",
    "    del i['Tags'] # I am not going to use\n",
    "    del i['Tags2'] # I am not going to use \n",
    "    del i['Picture2'] # I am not going to use \n",
    "    del i['Multimedia Example'] # I am not going to use\n",
    "    del i['Multimedia Example2 links'] # I am not going to use\n",
    "    del i['Note Image links'] # I am not going to use\n",
    "    del i['Word audio2 export links'] # I am not going to use\n",
    "    del i['Picture2 links'] # I am not going to use\n",
    "    del i['Multimedia Example2 export links'] # I am not going to use\n",
    "    del i['Note Image'] # I am not going to use\n",
    "    del i['Word audio'] # I am not going to use\n",
    "    del i['Word audio2 links'] # I am not going to use\n",
    "    del i['Multimedia Example2'] # I am not going to use\n",
    "    java_commands = open('java_commands.txt', 'a') # append to the file created\n",
    "    java_commands.write(\"Map<String, String> map\"+str(n)+ \" = new HashMap<String, String>();\" + '\\n')\n",
    "    for k, v in i.items():\n",
    "        java_commands.write(\"map\"+str(n)+ \".put(\\\"\"+str(k)+\"\\\"\"+\", \\\"\"+str(v)+\"\\\"\"+\");\" + '\\n')\n",
    "    java_commands.write(\"maps.add(map\"+str(n)+ \");\" + '\\n')\n",
    "    n += 1\n",
    "    java_commands.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "This it to be used in word_db.txt in MyWordDataDisplay project\n",
    "\"\"\"\n",
    "\n",
    "words_tem = word_gre_db\n",
    "#words_tem = word_db\n",
    "\n",
    "java_commands = open('java_commands.txt', 'w')\n",
    "java_commands.close()\n",
    "\n",
    "#n = 0\n",
    "for i in words_tem:\n",
    "    del i['Mnemonic'] # delete Mnemonic because it has '\"' character\n",
    "    del i['Note'] # I am not going to use Note\n",
    "    del i['Note Image export links'] # I am not going to use Note\n",
    "    del i['Other form'] # I am not going to use Other form\n",
    "    del i['Picture'] # I am not going to use Picture\n",
    "    del i['Word audio2'] # I am not going to use \n",
    "    del i['Tags'] # I am not going to use\n",
    "    del i['Tags2'] # I am not going to use \n",
    "    del i['Picture2'] # I am not going to use \n",
    "    del i['Multimedia Example'] # I am not going to use\n",
    "    del i['Multimedia Example2 links'] # I am not going to use\n",
    "    del i['Note Image links'] # I am not going to use\n",
    "    del i['Word audio2 export links'] # I am not going to use\n",
    "    del i['Picture2 links'] # I am not going to use\n",
    "    del i['Multimedia Example2 export links'] # I am not going to use\n",
    "    del i['Note Image'] # I am not going to use\n",
    "    del i['Word audio'] # I am not going to use\n",
    "    del i['Word audio2 links'] # I am not going to use\n",
    "    del i['Multimedia Example2'] # I am not going to use\n",
    "    java_commands = open('java_commands.txt', 'a') # append to the file created\n",
    "    #java_commands.write(\"Map<String, String> map\"+str(n)+ \" = new HashMap<String, String>();\" + '\\n')\n",
    "    for k, v in i.items():\n",
    "        java_commands.write(str(v)+'\\n')\n",
    "    #java_commands.write(\"maps.add(map\"+str(n)+ \");\" + '\\n')\n",
    "    #n += 1\n",
    "    java_commands.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Getting word_db ready for FlashVocab SQLlite export\n",
    "\n",
    "https://stackoverflow.com/questions/46835197/python-list-of-dictionary-stores-only-last-appended-value-in-every-iteration\n",
    "\"\"\"\n",
    "\n",
    "#words_tem = copy.deepcopy(word_gre_db)\n",
    "words_tem = copy.deepcopy(word_db)\n",
    "\n",
    "word_db2 = []\n",
    "\n",
    "card_key = 1\n",
    "for i in words_tem:\n",
    "    del i['Mnemonic'] # delete Mnemonic because it has '\"' character\n",
    "    del i['Note'] # I am not going to use Note\n",
    "    #del i['Note Image export links'] # I am not going to use Note\n",
    "    del i['Other form'] # I am not going to use Other form\n",
    "    del i['Picture'] # I am not going to use Picture\n",
    "    del i['Word audio2'] # I am not going to use \n",
    "    del i['Tags'] # I am not going to use\n",
    "    del i['Tags2'] # I am not going to use \n",
    "    del i['Picture2'] # I am not going to use \n",
    "    del i['Multimedia Example'] # I am not going to use\n",
    "    #del i['Multimedia Example2 links'] # I am not going to use\n",
    "    #del i['Note Image links'] # I am not going to use\n",
    "    #del i['Word audio2 export links'] # I am not going to use\n",
    "    #del i['Picture2 links'] # I am not going to use\n",
    "    #del i['Multimedia Example2 export links'] # I am not going to use\n",
    "    del i['Note Image'] # I am not going to use\n",
    "    del i['Word audio'] # I am not going to use\n",
    "    #del i['Word audio2 links'] # I am not going to use\n",
    "    del i['Multimedia Example2'] # I am not going to use\n",
    "    #del i['Picture2 export links']\n",
    "    for j in range(1, 4):\n",
    "        #i = dict(i) # shallow copy\n",
    "        i = copy.deepcopy(i)\n",
    "        i['Card Type'] = 'Type '+str(j)\n",
    "        i['Card Key'] = card_key\n",
    "        i['Schedule Score'] = 0\n",
    "        word_db2.append(i)\n",
    "        card_key += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Same thing as above, but for Google drive links\n",
    "Getting word_db ready for FlashVocab SQLlite export\n",
    "\n",
    "https://stackoverflow.com/questions/46835197/python-list-of-dictionary-stores-only-last-appended-value-in-every-iteration\n",
    "\"\"\"\n",
    "\n",
    "#words_tem = copy.deepcopy(word_gre_db)\n",
    "words_tem = copy.deepcopy(word_db)\n",
    "\n",
    "word_db2 = []\n",
    "\n",
    "card_key = 1\n",
    "for i in words_tem:\n",
    "    del i['Mnemonic']\n",
    "    del i['Note']\n",
    "    del i['Note Image export links']\n",
    "    del i['Other form']\n",
    "    del i['Picture']\n",
    "    del i['Word audio2'] \n",
    "    del i['Tags']\n",
    "    del i['Tags2'] \n",
    "    del i['Picture2']\n",
    "    del i['Multimedia Example']\n",
    "    del i['Multimedia Example2 links']\n",
    "    del i['Note Image links']\n",
    "    del i['Word audio2 export links']\n",
    "    del i['Picture2 links']\n",
    "    del i['Multimedia Example2 export links']\n",
    "    del i['Note Image']\n",
    "    del i['Word audio']\n",
    "    del i['Word audio2 links']\n",
    "    del i['Multimedia Example2']\n",
    "    #del i['Picture2 export links']\n",
    "    for j in range(1, 4):\n",
    "        #i = dict(i) # shallow copy\n",
    "        i = copy.deepcopy(i)\n",
    "        i['Card Type'] = 'Type '+str(j)\n",
    "        i['Card Key'] = card_key\n",
    "        i['Schedule Score'] = 0\n",
    "        word_db2.append(i)\n",
    "        card_key += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "New data model design - only one row for each work and 3 types of scores\n",
    "Same thing as above, but for Google drive links\n",
    "Getting word_db ready for FlashVocab SQLlite export\n",
    "\n",
    "https://stackoverflow.com/questions/46835197/python-list-of-dictionary-stores-only-last-appended-value-in-every-iteration\n",
    "\"\"\"\n",
    "\n",
    "words_tem = copy.deepcopy(word_gre_db)\n",
    "#words_tem = copy.deepcopy(word_db)\n",
    "\n",
    "word_db2 = []\n",
    "\n",
    "card_key = 1\n",
    "for i in words_tem:\n",
    "    del i['Mnemonic']\n",
    "    del i['Note']\n",
    "    del i['Note Image export links']\n",
    "    del i['Other form']\n",
    "    del i['Picture']\n",
    "    del i['Word audio2'] \n",
    "    del i['Tags']\n",
    "    del i['Tags2'] \n",
    "    del i['Picture2']\n",
    "    del i['Multimedia Example']\n",
    "    del i['Multimedia Example2 links']\n",
    "    del i['Note Image links']\n",
    "    del i['Word audio2 export links']\n",
    "    del i['Picture2 links']\n",
    "    del i['Multimedia Example2 export links']\n",
    "    del i['Note Image']\n",
    "    del i['Word audio']\n",
    "    del i['Word audio2 links']\n",
    "    del i['Multimedia Example2']\n",
    "    #del i['Picture2 export links']\n",
    "    i['Score WordCard'] = 0\n",
    "    i['Score MCQCard'] = 0\n",
    "    i['Score TypeinCard'] = 0\n",
    "    word_db2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "New data model design - only one row for each work and 3 types of scores\n",
    "Same thing as above, but for GCP links\n",
    "Getting word_db ready for FlashVocab SQLlite export\n",
    "\n",
    "https://stackoverflow.com/questions/46835197/python-list-of-dictionary-stores-only-last-appended-value-in-every-iteration\n",
    "\"\"\"\n",
    "\n",
    "words_tem = copy.deepcopy(word_gre_db)\n",
    "#words_tem = copy.deepcopy(word_db)\n",
    "\n",
    "word_db2 = []\n",
    "\n",
    "card_key = 1\n",
    "for i in words_tem:\n",
    "    del i['Mnemonic']\n",
    "    del i['Picture']\n",
    "    del i['Word audio2']\n",
    "    del i['Tags']\n",
    "    del i['Picture2']\n",
    "    del i['Note']\n",
    "    del i['Note Image']\n",
    "    del i['Word audio']\n",
    "    del i['Other form']\n",
    "    del i['Multimedia Example']\n",
    "    del i['Multimedia Example2']\n",
    "    del i['Tags2']\n",
    "    i['Score WordCard'] = 0\n",
    "    i['Score MCQCard'] = 0\n",
    "    i['Score TypeinCard'] = 0\n",
    "    word_db2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Writes out the generated word_db2\n",
    "\n",
    "word_db2_links_GCS_sorted.csv\n",
    "word_db2_links_GCS_gre_sorted.csv\n",
    "\"\"\"\n",
    "\n",
    "sort_dict_column(folder + os.sep + 'word_db2_links_GCS_gre_sorted.csv', word_db2)\n",
    "#sort_dict_column(folder + os.sep + 'word_db2_links_GCS_gre_sorted.csv', word_db2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This it to be used in word_db.txt in MyWordDataDisplay project\n",
    "\"\"\"\n",
    "\n",
    "words_tem = copy.deepcopy(word_db2)\n",
    "\n",
    "java_commands = open('java_commands.txt', 'w')\n",
    "java_commands.close()\n",
    "\n",
    "for i in words_tem:\n",
    "    java_commands = open('java_commands.txt', 'a') # append to the file created\n",
    "    i = collections.OrderedDict(sorted(i.items()))\n",
    "    for k, v in i.items():\n",
    "        java_commands.write(str(v)+'\\n')\n",
    "    java_commands.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
