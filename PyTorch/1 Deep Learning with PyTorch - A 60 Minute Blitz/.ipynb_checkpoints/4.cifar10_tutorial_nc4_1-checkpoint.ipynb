{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load and normalizing the CIFAR10 training and test datasets using torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a Convolution Neural Network\n",
    "--------------------------------------\n",
    "Copy the neural network from the Neural Networks section before and modify it to\n",
    "take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 48, 5) # 3 instead of 1\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(48, 128, 5)\n",
    "        self.fc1 = nn.Linear(128 * 5 * 5, 1600)\n",
    "        self.fc2 = nn.Linear(1600, 800)\n",
    "        self.fc3 = nn.Linear(800, 400)\n",
    "        self.fc4 = nn.Linear(400, 120)\n",
    "        self.fc5 = nn.Linear(120, 84)\n",
    "        self.fc6 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 128 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a Loss function and optimizer\n",
    "---------------------------------------\n",
    "\n",
    "Let's use a Classification Cross-Entropy loss and SGD with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train the network\n",
    "--------------------\n",
    "\n",
    "This is when things start to get interesting.\n",
    "We simply have to loop over our data iterator, and feed the inputs to the\n",
    "network and optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.303\n",
      "[1,  4000] loss: 2.302\n",
      "[1,  6000] loss: 2.250\n",
      "[1,  8000] loss: 1.908\n",
      "[1, 10000] loss: 1.763\n",
      "[1, 12000] loss: 1.647\n",
      "[2,  2000] loss: 1.512\n",
      "[2,  4000] loss: 1.475\n",
      "[2,  6000] loss: 1.393\n",
      "[2,  8000] loss: 1.315\n",
      "[2, 10000] loss: 1.260\n",
      "[2, 12000] loss: 1.216\n",
      "[3,  2000] loss: 1.114\n",
      "[3,  4000] loss: 1.060\n",
      "[3,  6000] loss: 1.042\n",
      "[3,  8000] loss: 1.045\n",
      "[3, 10000] loss: 1.006\n",
      "[3, 12000] loss: 0.965\n",
      "[4,  2000] loss: 0.836\n",
      "[4,  4000] loss: 0.815\n",
      "[4,  6000] loss: 0.819\n",
      "[4,  8000] loss: 0.817\n",
      "[4, 10000] loss: 0.796\n",
      "[4, 12000] loss: 0.810\n",
      "[5,  2000] loss: 0.597\n",
      "[5,  4000] loss: 0.633\n",
      "[5,  6000] loss: 0.647\n",
      "[5,  8000] loss: 0.654\n",
      "[5, 10000] loss: 0.627\n",
      "[5, 12000] loss: 0.655\n",
      "[6,  2000] loss: 0.437\n",
      "[6,  4000] loss: 0.471\n",
      "[6,  6000] loss: 0.476\n",
      "[6,  8000] loss: 0.486\n",
      "[6, 10000] loss: 0.508\n",
      "[6, 12000] loss: 0.497\n",
      "[7,  2000] loss: 0.282\n",
      "[7,  4000] loss: 0.341\n",
      "[7,  6000] loss: 0.349\n",
      "[7,  8000] loss: 0.357\n",
      "[7, 10000] loss: 0.362\n",
      "[7, 12000] loss: 0.371\n",
      "[8,  2000] loss: 0.206\n",
      "[8,  4000] loss: 0.224\n",
      "[8,  6000] loss: 0.258\n",
      "[8,  8000] loss: 0.258\n",
      "[8, 10000] loss: 0.263\n",
      "[8, 12000] loss: 0.272\n",
      "[9,  2000] loss: 0.152\n",
      "[9,  4000] loss: 0.162\n",
      "[9,  6000] loss: 0.181\n",
      "[9,  8000] loss: 0.189\n",
      "[9, 10000] loss: 0.204\n",
      "[9, 12000] loss: 0.189\n",
      "[10,  2000] loss: 0.088\n",
      "[10,  4000] loss: 0.128\n",
      "[10,  6000] loss: 0.120\n",
      "[10,  8000] loss: 0.137\n",
      "[10, 10000] loss: 0.130\n",
      "[10, 12000] loss: 0.170\n",
      "[11,  2000] loss: 0.077\n",
      "[11,  4000] loss: 0.095\n",
      "[11,  6000] loss: 0.103\n",
      "[11,  8000] loss: 0.114\n",
      "[11, 10000] loss: 0.113\n",
      "[11, 12000] loss: 0.099\n",
      "[12,  2000] loss: 0.050\n",
      "[12,  4000] loss: 0.079\n",
      "[12,  6000] loss: 0.077\n",
      "[12,  8000] loss: 0.086\n",
      "[12, 10000] loss: 0.096\n",
      "[12, 12000] loss: 0.077\n",
      "[13,  2000] loss: 0.040\n",
      "[13,  4000] loss: 0.039\n",
      "[13,  6000] loss: 0.053\n",
      "[13,  8000] loss: 0.078\n",
      "[13, 10000] loss: 0.068\n",
      "[13, 12000] loss: 0.056\n",
      "[14,  2000] loss: 0.043\n",
      "[14,  4000] loss: 0.050\n",
      "[14,  6000] loss: 0.058\n",
      "[14,  8000] loss: 0.070\n",
      "[14, 10000] loss: 0.051\n",
      "[14, 12000] loss: 0.058\n",
      "[15,  2000] loss: 0.051\n",
      "[15,  4000] loss: 0.050\n",
      "[15,  6000] loss: 0.061\n",
      "[15,  8000] loss: 0.051\n",
      "[15, 10000] loss: 0.048\n",
      "[15, 12000] loss: 0.054\n",
      "[16,  2000] loss: 0.018\n",
      "[16,  4000] loss: 0.044\n",
      "[16,  6000] loss: 0.037\n",
      "[16,  8000] loss: 0.045\n",
      "[16, 10000] loss: 0.042\n",
      "[16, 12000] loss: 0.034\n",
      "[17,  2000] loss: 0.038\n",
      "[17,  4000] loss: 0.030\n",
      "[17,  6000] loss: 0.044\n",
      "[17,  8000] loss: 0.042\n",
      "[17, 10000] loss: 0.038\n",
      "[17, 12000] loss: 0.044\n",
      "[18,  2000] loss: 0.021\n",
      "[18,  4000] loss: 0.032\n",
      "[18,  6000] loss: 0.018\n",
      "[18,  8000] loss: 0.027\n",
      "[18, 10000] loss: 0.029\n",
      "[18, 12000] loss: 0.037\n",
      "[19,  2000] loss: 0.020\n",
      "[19,  4000] loss: 0.016\n",
      "[19,  6000] loss: 0.031\n",
      "[19,  8000] loss: 0.038\n",
      "[19, 10000] loss: 0.025\n",
      "[19, 12000] loss: 0.032\n",
      "[20,  2000] loss: 0.023\n",
      "[20,  4000] loss: 0.025\n",
      "[20,  6000] loss: 0.027\n",
      "[20,  8000] loss: 0.022\n",
      "[20, 10000] loss: 0.023\n",
      "[20, 12000] loss: 0.032\n",
      "[21,  2000] loss: 0.021\n",
      "[21,  4000] loss: 0.024\n",
      "[21,  6000] loss: 0.025\n",
      "[21,  8000] loss: 0.025\n",
      "[21, 10000] loss: 0.030\n",
      "[21, 12000] loss: 0.033\n",
      "[22,  2000] loss: 0.019\n",
      "[22,  4000] loss: 0.025\n",
      "[22,  6000] loss: 0.018\n",
      "[22,  8000] loss: 0.021\n",
      "[22, 10000] loss: 0.029\n",
      "[22, 12000] loss: 0.030\n",
      "[23,  2000] loss: 0.009\n",
      "[23,  4000] loss: 0.011\n",
      "[23,  6000] loss: 0.017\n",
      "[23,  8000] loss: 0.016\n",
      "[23, 10000] loss: 0.019\n",
      "[23, 12000] loss: 0.022\n",
      "[24,  2000] loss: 0.011\n",
      "[24,  4000] loss: 0.010\n",
      "[24,  6000] loss: 0.027\n",
      "[24,  8000] loss: 0.022\n",
      "[24, 10000] loss: 0.022\n",
      "[24, 12000] loss: 0.018\n",
      "[25,  2000] loss: 0.019\n",
      "[25,  4000] loss: 0.016\n",
      "[25,  6000] loss: 0.011\n",
      "[25,  8000] loss: 0.020\n",
      "[25, 10000] loss: 0.029\n",
      "[25, 12000] loss: 0.017\n",
      "Finished Training\n",
      "('The network took ', 50854.18310904503, ' secs to train')\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(25):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "end_time = time.time()\n",
    "print(\"The network took \", end_time - start_time, \" secs to train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Test the network on the test data\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 74 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy per class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 79 %\n",
      "Accuracy of   car : 86 %\n",
      "Accuracy of  bird : 65 %\n",
      "Accuracy of   cat : 51 %\n",
      "Accuracy of  deer : 74 %\n",
      "Accuracy of   dog : 58 %\n",
      "Accuracy of  frog : 87 %\n",
      "Accuracy of horse : 76 %\n",
      "Accuracy of  ship : 83 %\n",
      "Accuracy of truck : 78 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze() # c will have 4, (0 or 1) values\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
